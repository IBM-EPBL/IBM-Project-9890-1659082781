import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Flatten,Dropout
from tensorflow.keras.layers import Convolution2D,MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
Augment the data

train = ImageDataGenerator(rescale = 1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)
test = ImageDataGenerator(rescale = 1./255)
Loading and augmentation of given data

import os, types
import pandas as pd
from botocore.client import Config
import ibm_boto3

def __iter__(self): return 0

# @hidden_cell
# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.
# You might want to remove those credentials before you share the notebook.
cos_client = ibm_boto3.client(service_name='s3',
    ibm_api_key_id='ruVWq-upAEIpwyjrYMpdqlosZ4JnX5RXtcSn70MT9ecX',
    ibm_auth_endpoint="https://iam.cloud.ibm.com/oidc/token",
    config=Config(signature_version='oauth'),
    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')

bucket = 'ibmimageclassification-donotdelete-pr-dljypkqhychmlp'
object_key = 'Dataset.zip'

streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']

# Your data file was loaded into a botocore.response.StreamingBody object.
# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.
# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/
# pandas documentation: http://pandas.pydata.org/
from io import BytesIO
import zipfile
unzip = zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')
fpath = unzip.namelist()
for i in fpath:
    unzip.extract(i)
pwd
'/home/wsuser/work'
import os
filename = os.listdir('/home/wsuser/work/Dataset/train')
import os
filename2 = os.listdir('/home/wsuser/work/Dataset/test')
A_train = train.flow_from_directory('/home/wsuser/work/Dataset/train', target_size=(64,64), color_mode='grayscale',batch_size=3, class_mode='categorical')
A_test = test.flow_from_directory('/home/wsuser/work/Dataset/test', target_size=(64,64), color_mode='grayscale',batch_size=3, class_mode='categorical')
Found 594 images belonging to 6 classes.
Found 30 images belonging to 6 classes.
print(A_train.class_indices)
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}
print(A_test.class_indices)
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}
Import Keras library

model = Sequential()
Add 1st Convolution Layer and Pooling layer

model.add(Convolution2D(32,(3,3),input_shape=(64,64,1),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
Add 2nd Convolution Layer and Pooling layer

model.add(Convolution2D(32,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
Add Flatten layer

model.add(Flatten())
Add dense layers

model.add(Dense(units=512,activation='relu'))
model.add(Dense(units=6,activation='softmax'))
model.summary()
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 62, 62, 32)        320       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 6272)              0         
                                                                 
 dense (Dense)               (None, 512)               3211776   
                                                                 
 dense_1 (Dense)             (None, 6)                 3078      
                                                                 
=================================================================
Total params: 3,224,422
Trainable params: 3,224,422
Non-trainable params: 0
_________________________________________________________________
Compile the model

model.compile(metrics=['accuracy'],loss='categorical_crossentropy',optimizer='adam')
Train the model

model.fit(A_train,steps_per_epoch = 594/3,epochs=25,validation_data=A_test,validation_steps=len(A_test))
Epoch 1/25
198/198 [==============================] - 13s 61ms/step - loss: 1.2947 - accuracy: 0.4983 - val_loss: 0.8564 - val_accuracy: 0.6667
Epoch 2/25
198/198 [==============================] - 12s 60ms/step - loss: 0.5856 - accuracy: 0.7407 - val_loss: 0.7670 - val_accuracy: 0.7667
Epoch 3/25
198/198 [==============================] - 12s 61ms/step - loss: 0.4245 - accuracy: 0.8502 - val_loss: 0.4064 - val_accuracy: 0.8667
Epoch 4/25
198/198 [==============================] - 12s 60ms/step - loss: 0.2823 - accuracy: 0.9074 - val_loss: 0.4233 - val_accuracy: 0.8333
Epoch 5/25
198/198 [==============================] - 12s 60ms/step - loss: 0.2197 - accuracy: 0.9175 - val_loss: 0.3531 - val_accuracy: 0.8667
Epoch 6/25
198/198 [==============================] - 12s 60ms/step - loss: 0.1884 - accuracy: 0.9259 - val_loss: 0.2322 - val_accuracy: 0.9667
Epoch 7/25
198/198 [==============================] - 12s 59ms/step - loss: 0.1547 - accuracy: 0.9495 - val_loss: 0.2573 - val_accuracy: 0.9000
Epoch 8/25
198/198 [==============================] - 12s 60ms/step - loss: 0.1387 - accuracy: 0.9545 - val_loss: 0.3020 - val_accuracy: 0.9000
Epoch 9/25
198/198 [==============================] - 12s 60ms/step - loss: 0.0997 - accuracy: 0.9562 - val_loss: 0.3950 - val_accuracy: 0.9667
Epoch 10/25
198/198 [==============================] - 12s 60ms/step - loss: 0.0929 - accuracy: 0.9680 - val_loss: 0.3173 - val_accuracy: 0.9333
Epoch 11/25
198/198 [==============================] - 12s 60ms/step - loss: 0.0520 - accuracy: 0.9815 - val_loss: 0.4534 - val_accuracy: 0.9667
Epoch 12/25
198/198 [==============================] - 12s 61ms/step - loss: 0.0570 - accuracy: 0.9798 - val_loss: 0.2890 - val_accuracy: 0.9667
Epoch 13/25
198/198 [==============================] - 12s 61ms/step - loss: 0.0683 - accuracy: 0.9747 - val_loss: 0.4490 - val_accuracy: 0.9333
Epoch 14/25
198/198 [==============================] - 12s 60ms/step - loss: 0.0488 - accuracy: 0.9916 - val_loss: 0.3521 - val_accuracy: 0.9667
Epoch 15/25
198/198 [==============================] - 12s 61ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.4235 - val_accuracy: 0.9667
Epoch 16/25
198/198 [==============================] - 12s 61ms/step - loss: 0.0898 - accuracy: 0.9680 - val_loss: 0.0253 - val_accuracy: 1.0000
Epoch 17/25
198/198 [==============================] - 12s 59ms/step - loss: 0.0804 - accuracy: 0.9697 - val_loss: 0.4834 - val_accuracy: 0.9667
Epoch 18/25
198/198 [==============================] - 12s 60ms/step - loss: 0.0589 - accuracy: 0.9832 - val_loss: 0.5656 - val_accuracy: 0.9667
Epoch 19/25
198/198 [==============================] - 12s 60ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.5061 - val_accuracy: 0.9667
Epoch 20/25
198/198 [==============================] - 12s 60ms/step - loss: 0.1126 - accuracy: 0.9630 - val_loss: 0.4193 - val_accuracy: 0.9333
Epoch 21/25
198/198 [==============================] - 12s 60ms/step - loss: 0.0486 - accuracy: 0.9781 - val_loss: 0.3418 - val_accuracy: 0.9667
Epoch 22/25
198/198 [==============================] - 12s 60ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.3969 - val_accuracy: 0.9667
Epoch 23/25
198/198 [==============================] - 12s 61ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.4430 - val_accuracy: 0.9333
Epoch 24/25
198/198 [==============================] - 12s 60ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.8502 - val_accuracy: 0.9667
Epoch 25/25
198/198 [==============================] - 12s 60ms/step - loss: 0.0661 - accuracy: 0.9747 - val_loss: 0.2539 - val_accuracy: 0.9667
Save the model

model.save('gesture.h5')
json_model = model.to_json()
with open("model-gesture.json","w") as json_file:
  json_file.write(json_model)
import os, types
import pandas as pd
from botocore.client import Config
import ibm_boto3

def __iter__(self): return 0

# @hidden_cell
# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.
# You might want to remove those credentials before you share the notebook.
cos_client = ibm_boto3.client(service_name='s3',
    ibm_api_key_id='ruVWq-upAEIpwyjrYMpdqlosZ4JnX5RXtcSn70MT9ecX',
    ibm_auth_endpoint="https://iam.cloud.ibm.com/oidc/token",
    config=Config(signature_version='oauth'),
    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')

bucket = 'ibmimageclassification-donotdelete-pr-dljypkqhychmlp'
object_key = 'imagetester.zip'

streaming_body_5 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']

# Your data file was loaded into a botocore.response.StreamingBody object.
# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.
# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/
# pandas documentation: http://pandas.pydata.org/
from io import BytesIO
import zipfile
unzip = zipfile.ZipFile(BytesIO(streaming_body_5.read()),'r')
fpath = unzip.namelist()
for i in fpath:
    unzip.extract(i)
import os
filename2 = os.listdir('/home/wsuser/work/Dataset')
ls
4.jpg     gesture.h5            model-gesture.json  test_image2.jpg
Dataset/  gesture_model.tar.gz  model-gesture.tgz   test_image.jpg
Test the model

!pip install watson-machine-learning-client --upgrade
Requirement already satisfied: watson-machine-learning-client in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.0.391)
Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)
Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)
Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)
Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)
Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)
Requirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)
Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)
Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)
Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)
Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)
Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)
Requirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)
Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)
Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)
Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)
Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)
Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)
Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)
Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)
from ibm_watson_machine_learning import APIClient
wml_credentials = {
                    "url":"https://us-south.ml.cloud.ibm.com",
                     "apikey":"UmH36wZ05c7Y8sHKX0hT46II80oRbd5YZtuhSGrMbSdv"
}
client = APIClient(wml_credentials)
def guid_from_space_name(client,space_name):
    space = client.spaces.get_details()
    return(next(item for item in space['resources'] if item['entity']["name"] == space_name)['metadata']['id'])
space_uid = guid_from_space_name(client,'IBMImageClassificationModel')
print("Space uid = ", space_uid)
Space uid =  f2e92fb4-0cc5-4b0f-8513-080137c29b49
client.set.default_space(space_uid)
'SUCCESS'
client.software_specifications.list()
-----------------------------  ------------------------------------  ----
NAME                           ASSET_ID                              TYPE
default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base
kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base
pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base
scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base
spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base
pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base
ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base
shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base
tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base
pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base
tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base
autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base
runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base
scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base
default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base
pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base
kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base
pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base
tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base
spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base
tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base
runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base
do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base
autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base
tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base
kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base
pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base
spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base
pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base
spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base
spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base
autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base
xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base
pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base
pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base
default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base
autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base
autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base
pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base
spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base
xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base
pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base
autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base
spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base
spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base
autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base
spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base
cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base
autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base
pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base
-----------------------------  ------------------------------------  ----
Note: Only first 50 records were displayed. To display more use 'limit' parameter.
software_spec_uid = client.software_specifications.get_uid_by_name("tensorflow_rt22.1-py3.9")
software_spec_uid
'acd9c798-6974-5d2f-a657-ce06e986df4d'
!tar -zcvf model-gesture.tgz gesture.h5
gesture.h5
ls
4.jpg     gesture.h5          model-gesture.tgz  test_image.jpg
Dataset/  model-gesture.json  test_image2.jpg
model_details = client.repository.store_model(model="model-gesture.tgz",meta_props={
    client.repository.ModelMetaNames.NAME:"CNN",
    client.repository.ModelMetaNames.TYPE:"tensorflow_2.7",
    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid
}
                                             )
model_id = client.repository.get_model_id(model_details)
model_id
'997ddf5c-d58e-4cc2-85e3-324254945d3d'
client.repository.download(model_id,'gesture_model.tar.gz')
Successfully saved model content to file: 'gesture_model.tar.gz'
'/home/wsuser/work/gesture_model.tar.gz'
ls
4.jpg     gesture.h5            model-gesture.json  test_image2.jpg
Dataset/  gesture_model.tar.gz  model-gesture.tgz   test_image.jpg
rm gesture_model.tar.gz
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
test_model = load_model('gesture.h5')
img_path= "/home/wsuser/work/4.jpg"
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img = mpimg.imread(img_path)
imgplot = plt.imshow(img)
plt.show()

imgload = image.load_img(img_path,color_mode='grayscale',target_size=(64,64))
res = image.img_to_array(imgload)
res.shape
(64, 64, 1)
type(res)
numpy.ndarray
res = np.expand_dims(res,axis=0)
res.shape
(1, 64, 64, 1)
Predict the result

pred_res = np.argmax(test_model.predict(res),axis=-1)
pred_res
array([1])
index = ['0','1','2','3','4','5']
final_res = str(index[pred_res[0]])
final_res
'1'
